{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSI - Zadanie 4 <br/>\n",
    "### 4.12.2023 <br/>\n",
    "Wojciech Pobocha\n",
    "318399\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funkcje służące do przygotowania danych do trenowania i testowania modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, ratio):\n",
    "    dataLength = len(data)\n",
    "    numberOfTrain = int(dataLength * ratio)\n",
    "    test = data.iloc[numberOfTrain:dataLength]\n",
    "    train = data.iloc[0:numberOfTrain]\n",
    " \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepeatedValues(column):\n",
    "    values = []\n",
    "    for i in range(0, len(column)):\n",
    "        if column[i] not in values:\n",
    "            values.append(column[i])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding(data, columnNames):\n",
    "    valuesDictionary = {}\n",
    "    for columnName in columnNames:\n",
    "        column = data[columnName]\n",
    "        repeatedValues = getRepeatedValues(column)\n",
    "        valuesDictionary[columnName] = repeatedValues\n",
    "        for i in range(0, len(repeatedValues)):\n",
    "            data[columnName] = data[columnName].replace(repeatedValues[i], i)\n",
    "    return data, valuesDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeOneHotEncoding(data, decodingDictionary):\n",
    "    for column in decodingDictionary:\n",
    "        for i in range(0, len(decodingDictionary[column])):\n",
    "            data[column] = data[column].replace(i, decodingDictionary[column][i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataset(data, columnNames, threshold):\n",
    "    data['passed exam'] = -1\n",
    "    for i in range(0, len(data)):\n",
    "        for column in columnNames:\n",
    "            if data[column][i] <= threshold:\n",
    "                data['passed exam'][i] = 1\n",
    "                break\n",
    "    data.drop(columnNames, axis=1, inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definicja funkcji jądrowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbfKernel(u, v, sigma=1):\n",
    "    return np.exp(-np.linalg.norm(u-v)**2/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearKernel(u, v):\n",
    "    return np.dot(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definicja funkcji decyzyjnej\n",
    "Parametry funkcji:\n",
    "- `x` - argument funkcji,\n",
    "- `parameters` - wektor parametrów (alpha1,...,alphaN,b), dłuższe od X o 1, by uwzględnić parametr b, został wybrany na podstawie minimalizacji funkcji celu\n",
    "- `X` -  wektor argumentów modelu, pochodzący z danych treningowych\n",
    "- `Y` - wektor oczekiwanych wartości module, pochodzący z danych treningowych\n",
    "- `kernel` - funkcja jądrowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, parameters, b, X, Y, kernel):\n",
    "    sum = 0\n",
    "    for i in range(len(X)):\n",
    "        sum += parameters[i] * Y[i] * kernel(X[i], x)\n",
    "    sum += -b\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wNormSquare(X, Y, parameters, kernel):\n",
    "    sum = 0\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X)):\n",
    "            sum += parameters[i] * parameters[j] * Y[i] * Y[j] * kernel(X[i], X[j])\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funkcja celu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionToMinimize(parameters, X, Y, kernel, C):\n",
    "    sum = 0\n",
    "    for i in range(len(X)):\n",
    "        sum += max(1-f(X[i],parameters,parameters[-1],X,Y,kernel)*Y[i], 0)\n",
    "    sum += C * wNormSquare(X,Y,parameters,kernel)\n",
    "    return sum\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient funkcji celu\n",
    "\n",
    "Wzór gradientu wyprowadzony analitycznie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientFunctionToMinimize(parameters, X, Y, kernel, C):\n",
    "    gradient = np.zeros(len(X)+1)\n",
    "    for n in range(len(X)):\n",
    "        condition = 1-f(X[n],parameters,parameters[-1],X,Y,kernel)*Y[n]\n",
    "        firstSum = 0\n",
    "        secondSum = 0\n",
    "        for i in range(len(X)):\n",
    "            if condition > 0:\n",
    "                firstSum += (-parameters[n]*Y[n]*kernel(X[n], X[i]))*Y[i]\n",
    "            secondSum += parameters[n]*Y[n]*Y[i]*kernel(X[n], X[i]) + parameters[i]* Y[i]*Y[n]*kernel(X[i], X[n])\n",
    "        gradient[n] = firstSum + C * secondSum\n",
    "        if condition > 0:\n",
    "            gradient[-1] += Y[n]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funkcja służąca do minimalizacji parametrów (alpha1,...alphaN,b)\n",
    "\n",
    "Skorzystałem z algorytmu najmniejszego spadku implementowanego na pierwszym laboratorium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastestDescent(alfa, maxIterations, startingPoint, gradient,functionToMinimize):\n",
    "    valuesVector = np.array([startingPoint])\n",
    "    dimension = valuesVector.shape[1]\n",
    "    iterations = 1\n",
    "    bestValue = np.inf\n",
    "    gradientVector = gradient(valuesVector[0])\n",
    "    while iterations < maxIterations:\n",
    "        valuesVector = np.vstack((valuesVector,np.zeros(dimension)))\n",
    "        currentValue = functionToMinimize(valuesVector[iterations-1])\n",
    "        if bestValue > currentValue:\n",
    "            bestParameters = valuesVector[iterations-1]\n",
    "            bestValue = currentValue\n",
    "        valuesVector[iterations] = valuesVector[iterations-1] - alfa * gradientVector\n",
    "        \n",
    "        gradientVector = gradient(valuesVector[iterations])\n",
    "        iterations +=1\n",
    "\n",
    "    return bestParameters, valuesVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmGradientAdapter(X, Y, kernel, C):\n",
    "    def svmGradient(parameters):\n",
    "        return gradientFunctionToMinimize(parameters, X, Y, kernel, C)\n",
    "    return svmGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmFunctionToMinimizeAdapter(X, Y, kernel, C):\n",
    "    def svmFunctionToMinimize(parameters):\n",
    "        return functionToMinimize(parameters, X, Y, kernel, C)\n",
    "    return svmFunctionToMinimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExamsDataSets(ratio=0.1):\n",
    "    data = pd.read_csv('data/exams.csv')\n",
    "    columnsToEncode = ['gender','race/ethnicity',\t'parental level of education',\t'lunch',\t'test preparation course']\n",
    "    data, decodingDictionary = oneHotEncoding(data,columnsToEncode)\n",
    "    data = labelDataset(data, ['math score', 'reading score', 'writing score'], 60)\n",
    "    train, test = splitData(data, ratio)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeData(data):\n",
    "    X = np.vstack([data['gender'],data['race/ethnicity'],data['parental level of education'],data['lunch'],data['test preparation course']]).T\n",
    "    Y = data['passed exam'].to_numpy()\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitSVM(X,Y,kernel,C):\n",
    "    startingParameters = np.random.uniform(-10,10,len(X)+1)\n",
    "    parameters, valuesVector = fastestDescent(0.01, 1000, startingParameters, svmGradientAdapter(X, Y, kernel, C), svmFunctionToMinimizeAdapter(X, Y, kernel, C))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definicja metryk służących do oceny modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getConfusionMatrix(testSetXs, testSetYs,trainSetX,trainSetY, kernel, parameters, b):\n",
    "    confusionMatrix = np.zeros((2,2))\n",
    "    for i in range(len(testSetXs)):\n",
    "        val = f(testSetXs[i],parameters,b,trainSetX,trainSetY,kernel)\n",
    "        if val < 0:\n",
    "            if testSetYs[i] > 0:\n",
    "                confusionMatrix[0][1] += 1\n",
    "            else:\n",
    "                confusionMatrix[0][0] += 1\n",
    "        else:\n",
    "            if testSetYs[i] < 0:\n",
    "                confusionMatrix[1][0] += 1\n",
    "            else:\n",
    "                confusionMatrix[1][1] += 1\n",
    "    return confusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(confusionMatrix):\n",
    "    return (confusionMatrix[0][0] + confusionMatrix[1][1]) / np.sum(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrecision(confusionMatrix):\n",
    "    return confusionMatrix[0][0] / (confusionMatrix[0][0] + confusionMatrix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecall(confusionMatrix):\n",
    "    return confusionMatrix[0][0] / (confusionMatrix[0][0] + confusionMatrix[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = getExamsDataSets(0.1)\n",
    "X, Y = vectorizeData(train)\n",
    "XTest, YTest = vectorizeData(test)\n",
    "kernel = rbfKernel\n",
    "C=1\n",
    "parameters = fitSVM(X,Y,kernel,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[348. 276.]\n",
      " [170. 106.]]\n",
      "0.5044444444444445\n",
      "0.5576923076923077\n",
      "0.6718146718146718\n"
     ]
    }
   ],
   "source": [
    "matrix = getConfusionMatrix(XTest, YTest, X, Y, kernel, parameters, parameters[-1])\n",
    "print(matrix)\n",
    "print(getAccuracy(matrix))\n",
    "print(getPrecision(matrix))\n",
    "print(getRecall(matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Komentarz do wyników\n",
    "Niestety wyniki są niezadowalające, prawdopodobnie popełniłem błąd w implementacji gradientu funkcji, jednak nie mogłem go znaleźć. Oprócz tego, testowanie algorytmu jest bardzo wolne, dlatego zbiór trenujący jest taki mały w porównaniu do testującego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144501/206866904.py:5: RuntimeWarning: overflow encountered in scalar add\n",
      "  sum += parameters[i] * parameters[j] * Y[i] * Y[j] * kernel(X[i], X[j])\n",
      "/tmp/ipykernel_144501/206866904.py:5: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  sum += parameters[i] * parameters[j] * Y[i] * Y[j] * kernel(X[i], X[j])\n",
      "/tmp/ipykernel_144501/206866904.py:5: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  sum += parameters[i] * parameters[j] * Y[i] * Y[j] * kernel(X[i], X[j])\n",
      "/tmp/ipykernel_144501/882997021.py:4: RuntimeWarning: overflow encountered in scalar add\n",
      "  sum += max(1-f(X[i],parameters,parameters[-1],X,Y,kernel)*Y[i], 0)\n",
      "/tmp/ipykernel_144501/236129591.py:10: RuntimeWarning: overflow encountered in scalar add\n",
      "  secondSum += parameters[n]*Y[n]*Y[i]*kernel(X[n], X[i]) + parameters[i]* Y[i]*Y[n]*kernel(X[i], X[n])\n",
      "/tmp/ipykernel_144501/2821799041.py:4: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  sum += parameters[i] * Y[i] * kernel(X[i], x)\n",
      "/tmp/ipykernel_144501/236129591.py:10: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  secondSum += parameters[n]*Y[n]*Y[i]*kernel(X[n], X[i]) + parameters[i]* Y[i]*Y[n]*kernel(X[i], X[n])\n",
      "/tmp/ipykernel_144501/236129591.py:10: RuntimeWarning: invalid value encountered in scalar add\n",
      "  secondSum += parameters[n]*Y[n]*Y[i]*kernel(X[n], X[i]) + parameters[i]* Y[i]*Y[n]*kernel(X[i], X[n])\n",
      "/tmp/ipykernel_144501/236129591.py:9: RuntimeWarning: overflow encountered in scalar add\n",
      "  firstSum += (-parameters[n]*Y[n]*kernel(X[n], X[i]))*Y[i]\n",
      "/tmp/ipykernel_144501/236129591.py:9: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  firstSum += (-parameters[n]*Y[n]*kernel(X[n], X[i]))*Y[i]\n"
     ]
    }
   ],
   "source": [
    "train, test = getExamsDataSets(0.1)\n",
    "X, Y = vectorizeData(train)\n",
    "XTest, YTest = vectorizeData(test)\n",
    "kernel = linearKernel\n",
    "C=1\n",
    "parameters = fitSVM(X,Y,kernel,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.]\n",
      " [518. 382.]]\n",
      "0.42444444444444446\n"
     ]
    }
   ],
   "source": [
    "matrix = getConfusionMatrix(XTest, YTest, X, Y, kernel, parameters, parameters[-1])\n",
    "print(matrix)\n",
    "print(getAccuracy(matrix))\n",
    "# print(getPrecision(matrix))\n",
    "# print(getRecall(matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie algorytmu i eksperymentów\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
