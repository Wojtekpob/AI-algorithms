{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, ratio):\n",
    "    dataLength = len(data)\n",
    "    numberOfTrain = int(dataLength * ratio)\n",
    "    test = data.iloc[numberOfTrain:dataLength]\n",
    "    train = data.iloc[0:numberOfTrain]\n",
    " \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepeatedValues(column):\n",
    "    values = []\n",
    "    for i in range(0, len(column)):\n",
    "        if column[i] not in values:\n",
    "            values.append(column[i])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding(data, columnNames):\n",
    "    valuesDictionary = {}\n",
    "    for columnName in columnNames:\n",
    "        column = data[columnName]\n",
    "        repeatedValues = getRepeatedValues(column)\n",
    "        valuesDictionary[columnName] = repeatedValues\n",
    "        for i in range(0, len(repeatedValues)):\n",
    "            data[columnName] = data[columnName].replace(repeatedValues[i], i)\n",
    "    return data, valuesDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeOneHotEncoding(data, decodingDictionary):\n",
    "    for column in decodingDictionary:\n",
    "        for i in range(0, len(decodingDictionary[column])):\n",
    "            data[column] = data[column].replace(i, decodingDictionary[column][i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataset(data, columnNames, threshold):\n",
    "    data['passed exam'] = -1\n",
    "    for i in range(0, len(data)):\n",
    "        for column in columnNames:\n",
    "            if data[column][i] <= threshold:\n",
    "                data['passed exam'][i] = 1\n",
    "                break\n",
    "    data.drop(columnNames, axis=1, inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender race/ethnicity parental level of education         lunch  \\\n",
      "0    male        group A                 high school      standard   \n",
      "1  female        group D            some high school  free/reduced   \n",
      "2    male        group E                some college  free/reduced   \n",
      "3    male        group B                 high school      standard   \n",
      "4    male        group E          associate's degree      standard   \n",
      "\n",
      "  test preparation course  math score  reading score  writing score  \n",
      "0               completed          67             67             63  \n",
      "1                    none          40             59             55  \n",
      "2                    none          59             60             50  \n",
      "3                    none          77             78             68  \n",
      "4               completed          78             73             68  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/exams.csv')\n",
    "columnsToEncode = ['gender','race/ethnicity',\t'parental level of education',\t'lunch',\t'test preparation course']\n",
    "print(data.head())\n",
    "data, decodingDictionary = oneHotEncoding(data,columnsToEncode)\n",
    "data = labelDataset(data, ['math score', 'reading score', 'writing score'], 60)\n",
    "train, test = splitData(data, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbfKernel(u, v, sigma=1):\n",
    "    return np.exp(-np.linalg.norm(u-v)**2/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearKernel(u, v):\n",
    "    return np.dot(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, parameters, b, X, Y, kernel):\n",
    "    sum = 0\n",
    "    for i in range(len(X)):\n",
    "        sum += parameters[i] * Y[i] * kernel(X[i], x) - b\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wNormSquare(X, Y, parameters, kernel):\n",
    "    sum = 0\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X)):\n",
    "            sum += parameters[i] * parameters[j] * Y[i] * Y[j] * kernel(X[i], X[j])\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionToMinimize(parameters, X, Y, kernel, C):\n",
    "    sum = 0\n",
    "    for i in range(len(X)):\n",
    "        sum += max(1-f(X[i],parameters,parameters[-1],X,Y,kernel), 0)\n",
    "    sum += C * wNormSquare(X,Y,parameters,kernel)\n",
    "    return sum\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters to wektor pionowy wszystkich alf i b na koÅ„cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientFunctionToMinimize(parameters, X, Y, kernel, C):\n",
    "    gradient = np.zeros(len(X)+1)\n",
    "    for n in range(len(X)):\n",
    "        firstSum = 0\n",
    "        secondSum = 0\n",
    "        for i in range(len(X)):\n",
    "            firstSum += max((-parameters[n]*Y[n]*kernel(X[n], X[i]))*Y[i], 0)\n",
    "            secondSum += parameters[n]*Y[n]*Y[i]*kernel(X[n], X[i]) + parameters[i]* Y[i]*Y[n]*kernel(X[i], X[n])\n",
    "        gradient[n] = firstSum + C * secondSum\n",
    "    for i in range(len(X)):\n",
    "        gradient[-1] += max(-parameters[-1]*Y[i],0)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastestDescent(alfa, epsilon, startingPoint, gradient,functionToMinimize):\n",
    "    valuesVector = np.array([startingPoint])\n",
    "    dimension = valuesVector.shape[1]\n",
    "    iterations = 1\n",
    "    bestValue = np.inf\n",
    "    # bestParameters = []\n",
    "    gradientNorm = np.linalg.norm(gradient(valuesVector[0]))\n",
    "    while gradientNorm>epsilon:\n",
    "        valuesVector = np.vstack((valuesVector,np.zeros(dimension)))\n",
    "        valuesVector[iterations] = valuesVector[iterations-1] - alfa * gradientNorm\n",
    "        currentValue = functionToMinimize(valuesVector[iterations])\n",
    "        if bestValue > currentValue:\n",
    "            bestParameters = valuesVector[iterations-1] # zmiejszyc training set, zwracac bestParameters\n",
    "            bestValue = currentValue\n",
    "        gradientNorm = np.linalg.norm(gradient(valuesVector[iterations]))\n",
    "        iterations +=1\n",
    "\n",
    "    return bestParameters, valuesVector, iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmGradientAdapter(X, Y, kernel, C):\n",
    "    def svmGradient(parameters):\n",
    "        return gradientFunctionToMinimize(parameters, X, Y, kernel, C)\n",
    "    return svmGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmFunctionToMinimizeAdapter(X, Y, kernel, C):\n",
    "    def svmFunctionToMinimize(parameters):\n",
    "        return functionToMinimize(parameters, X, Y, kernel, C)\n",
    "    return svmFunctionToMinimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33428/1509009728.py:4: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  sum += parameters[i] * Y[i] * kernel(X[i], x) - b\n",
      "/tmp/ipykernel_33428/1509009728.py:4: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  sum += parameters[i] * Y[i] * kernel(X[i], x) - b\n",
      "/tmp/ipykernel_33428/206866904.py:5: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  sum += parameters[i] * parameters[j] * Y[i] * Y[j] * kernel(X[i], X[j])\n",
      "/tmp/ipykernel_33428/2434013257.py:7: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  firstSum += max((-parameters[n]*Y[n]*kernel(X[n], X[i]))*Y[i], 0)\n",
      "/tmp/ipykernel_33428/2434013257.py:8: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  secondSum += parameters[n]*Y[n]*Y[i]*kernel(X[n], X[i]) + parameters[i]* Y[i]*Y[n]*kernel(X[i], X[n])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-897.28576463 -897.23884585 -898.62238268 -897.20338799 -896.87421696\n",
      " -896.87453741 -897.5532464  -897.20495486 -898.56947415 -898.32337589\n",
      " -897.18226512 -897.21738689 -897.08206627 -897.01608066 -897.11745795\n",
      " -897.73953205 -898.47090673 -898.26003076 -898.20348146 -897.28692419\n",
      " -897.58642854 -896.76436532 -898.40612242 -898.28490354 -898.14493493\n",
      " -898.34918787 -898.48192285 -898.3792141  -897.85290697 -898.19678023\n",
      " -897.32679757 -897.23218644 -897.14297763 -897.58480755 -897.88075044\n",
      " -898.53920512 -896.94478874 -897.53437486 -897.17368541 -897.54978556\n",
      " -896.98713033 -897.98333857 -898.10204716 -898.29028238 -897.67844382\n",
      " -898.63106588 -897.41125949 -898.23513149 -897.79575946 -897.55837353\n",
      " -898.67904439 -896.96766396 -896.98223849 -897.7842484  -898.72536329\n",
      " -897.84728774 -898.4788717  -898.14073976 -897.98633017 -896.94755735\n",
      " -898.30852869 -898.18913236 -897.52287143 -897.26066556 -898.16166314\n",
      " -897.54618743 -897.71755768 -898.67552721 -898.42396249 -898.33421905\n",
      " -897.048001   -898.52799231 -897.50200418 -897.07110111 -897.8670316\n",
      " -898.0316026  -896.76782245 -898.5459454  -896.80926863 -897.32591291\n",
      " -897.31713386 -897.41903276 -898.37773035 -897.76092234 -897.63039177\n",
      " -896.83377518 -898.23489207 -897.53039277 -897.05406306 -896.79010885\n",
      " -897.64544096 -898.097621   -897.22642637 -896.77503608 -897.49663327\n",
      " -897.74611519 -897.79963186 -896.85244967 -897.85026786 -897.10600489\n",
      " -898.19434507 -898.13819521 -898.55607169 -898.65286118 -898.55461264\n",
      " -897.92405188 -897.31392569 -896.78923105 -897.86443467 -897.7070775\n",
      " -897.11418564 -898.4456894  -897.9318772  -898.24888302 -897.92761095\n",
      " -897.43838614 -897.26521035 -897.23043264 -898.42386004 -897.55326327\n",
      " -898.35274519 -896.7934478  -897.20049219 -896.99791179 -897.92137839\n",
      " -898.57190388 -897.82891196 -897.81032845 -897.31469804 -897.74921977\n",
      " -897.45738024 -897.91946014 -898.626705   -897.39256696 -897.63214514\n",
      " -898.33059891 -897.54230808 -896.85186564 -897.78956743 -898.49367813\n",
      " -897.6281005  -897.67728781 -897.76614438 -898.42071956 -897.39981619\n",
      " -897.8465124  -898.5302781  -897.25279993 -897.67883823 -897.90625807\n",
      " -898.46728799 -898.13135992 -897.24749704 -898.54822192 -898.122611\n",
      " -897.95945218 -896.77845521 -897.24324288 -898.45116602 -897.97834708\n",
      " -897.68598033 -898.59018862 -897.70690458 -898.699087   -897.77794857\n",
      " -897.46870761 -897.67597109 -897.71767143 -897.68069443 -898.38418528\n",
      " -897.96038376 -897.86423257 -897.41490281 -896.75017397 -897.30792011\n",
      " -897.57542853 -897.18788371 -896.89804484 -898.02067201 -897.3432155\n",
      " -896.95824859 -898.47672806 -898.34535546 -898.47949066 -897.73694596\n",
      " -898.15850118 -896.79382579 -898.73198257 -898.03744193 -897.10440044\n",
      " -897.75712806 -898.12310531 -897.40314396 -897.42633029 -897.53500602\n",
      " -897.27883954 -896.95574489 -897.54130403 -897.33480628 -898.00333059\n",
      " -896.92774777]\n",
      "5245474561.236891\n"
     ]
    }
   ],
   "source": [
    "# X = train[['gender','race/ethnicity',\t'parental level of education',\t'lunch',\t'test preparation course']]\n",
    "X = np.vstack([train['gender'],train['race/ethnicity'],train['parental level of education'],train['lunch'],train['test preparation course']]).T\n",
    "Y = train['passed exam'].to_numpy()\n",
    "C = 1\n",
    "kernel = rbfKernel\n",
    "# kernel = linearKernel\n",
    "startingParameters = np.random.uniform(-1,1,len(X)+1)\n",
    "bestValue, valuesVector, iterations = fastestDescent(0.1, 0.1, startingParameters, svmGradientAdapter(X, Y, kernel, C), svmFunctionToMinimizeAdapter(X, Y, kernel, C))\n",
    "print(bestValue)\n",
    "print(svmFunctionToMinimizeAdapter(X, Y, kernel, C)(bestValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
