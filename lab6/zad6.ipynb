{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, ratio):\n",
    "    np.random.shuffle(data)\n",
    "    train_size = int(len(data) * ratio)\n",
    "    train_set = data[:train_size]\n",
    "    test_set = data[train_size:]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeToMinutes(time):\n",
    "    splitted = time.split(\":\")\n",
    "    if int(splitted[0]) > 23 or int(splitted[1]) > 59:\n",
    "        raise ValueError\n",
    "    return int(splitted[0]) * 60 + int(splitted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTime(time):\n",
    "    minutes = timeToMinutes(time)\n",
    "    return  math.sin(minutes / (24 * 60)*math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(codesToIndexes):\n",
    "    data = []\n",
    "    for i in range(1, 70):\n",
    "        filePrefix = 'Diabetes-Data/data-'\n",
    "        if i < 10:\n",
    "            filePrefix += '0'\n",
    "        fileHandle = open(filePrefix+str(i), 'r')\n",
    "        for line in fileHandle:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                try:\n",
    "                    parts = line.split('\\t')\n",
    "                    time = processTime(parts[1])\n",
    "                    code = int(parts[2])\n",
    "                    if code not in codesToIndexes.keys():\n",
    "                        raise ValueError\n",
    "                    number = int(parts[3])\n",
    "                    data.append([time, code, number])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        \n",
    "        fileHandle.close()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeOutput(Y,codesToIndexes):\n",
    "    codesToIndexes = {33:0, 34:1, 35:2, 48:3, 57:4, 58:5, 59:6, 60:7, 61:8, 62:9, 63:10, 64:11, 65:12, 66:13, 67:14, 68:15, 69:16, 70:17, 71:18, 72:19}\n",
    "    Y_encoded = np.zeros((Y.shape[0], 20))\n",
    "    for i, code in enumerate(Y):\n",
    "        index = codesToIndexes[code]\n",
    "        Y_encoded[i, index] = 1\n",
    "    return Y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "codesToIndexes = {33:0, 34:1, 35:2, 48:3, 57:4, 58:5, 59:6, 60:7, 61:8, 62:9, 63:10, 64:11, 65:12, 66:13, 67:14, 68:15, 69:16, 70:17, 71:18, 72:19}\n",
    "data = np.array(loadData(codesToIndexes))\n",
    "data, test = splitData(data, 0.8)\n",
    "X = data[:, [0, 2]]\n",
    "X_test = test[:, [0, 2]]\n",
    "Y = data[:, 1]\n",
    "Y_test = test[:, 1]\n",
    "Y_encoded = encodeOutput(Y,codesToIndexes)\n",
    "Y_test_encoded = encodeOutput(Y_test,codesToIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters(nX, nH, nY, numberOfHiddenLayers=1):\n",
    "    parameters = {}\n",
    "    if numberOfHiddenLayers < 1:\n",
    "        raise ValueError   \n",
    "    parameters[\"W1\"] = np.random.randn(nX, nH)\n",
    "    parameters[\"b1\"] = np.zeros((1,nH))\n",
    "    if numberOfHiddenLayers > 1:\n",
    "        for i in range(2, numberOfHiddenLayers):\n",
    "            parameters[\"W\"+str(i+1)] = np.random.randn(nH[i-2], nH[i-1])\n",
    "            parameters[\"b\"+str(i+1)] = np.zeros((1,nH[i-1]))\n",
    "    parameters[\"W\"+str(numberOfHiddenLayers+1)] = np.random.randn(nH, nY)\n",
    "    W1 = np.random.randn(nX, nH)\n",
    "    b1 = np.zeros((1,nH))\n",
    "    b1 = np.random.randn(1,nH)\n",
    "    W2 = np.random.randn(nH,nY)\n",
    "    b2 = np.zeros((1,nY))\n",
    "    b2 = np.random.randn(1,nY)\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architektura sieci neuronowej\n",
    "\n",
    "- **Warstwa wejściowa:** N neurony (wejścia)\n",
    "- **Warstwy ukryte:** L warstw, każda z dowolną liczbą neuronów\n",
    "- **Warstwa wyjściowa:** K neuronów (klasyfikacja na K kategorii)\n",
    "\n",
    "### Funkcje aktywacji\n",
    "\n",
    "- **Warstwy ukryte:** Sigmoid\n",
    "  - $$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "- **Warstwa wyjściowa:** Softmax\n",
    "  - $$\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n",
    "\n",
    "### Propagacja w przód\n",
    "\n",
    "Dla każdej warstwy l (od 1 do L+1, gdzie L+1 to warstwa wyjściowa):\n",
    "\n",
    "1. **Sygnał wejściowy:** $$Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$$\n",
    "2. **Aktywacja:** \n",
    "   - Dla warstw ukrytych: $$A^{[l]} = \\sigma(Z^{[l]})$$\n",
    "   - Dla warstwy wyjściowej: $$A^{[L+1]} = \\text{Softmax}(Z^{[L+1]})$$\n",
    "\n",
    "### Wsteczna propagacja błędu\n",
    "\n",
    "1. **Błąd na wyjściu (warstwa L+1):**\n",
    "   - $$\\delta^{[L+1]} = A^{[L+1]} - Y$$\n",
    "\n",
    "Dla każdej warstwy l od L do 1:\n",
    "\n",
    "2. **Błąd dla warstwy l:**\n",
    "   - $$\\delta^{[l]} = (W^{[l+1]T} \\delta^{[l+1]}) \\odot \\sigma'(Z^{[l]})$$\n",
    "3. **Gradient dla wag i biasów:**\n",
    "   - $$\\nabla W^{[l]} = \\delta^{[l]} A^{[l-1]T}$$\n",
    "   - $$\\nabla b^{[l]} = \\sum(\\delta^{[l]}, \\text{axis} = 0)$$\n",
    "\n",
    "### Aktualizacja wag\n",
    "\n",
    "- Wagi i biasy są aktualizowane za pomocą metody spadku gradientu:\n",
    "  - $$W^{[l]} = W^{[l]} - \\alpha \\nabla W^{[l]}$$\n",
    "  - $$b^{[l]} = b^{[l]} - \\alpha \\nabla b^{[l]}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(Y, Y_hat):\n",
    "    return - np.sum(Y * np.log(Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    return np.exp(Z) / np.sum(np.exp(Z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(X, Y, parameters):\n",
    "    Z1 = np.dot(X, parameters[\"W1\"]) + parameters[\"b1\"]\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, parameters[\"W2\"]) + parameters[\"b2\"]\n",
    "    A2 = softmax(Z2)\n",
    "    cost = costFunction(Y, A2)\n",
    "    # pochodne funkcji straty:\n",
    "    dA2 = A2 - Y\n",
    "    dW2 = np.dot(A1.T,dA2) \n",
    "    db2 = np.sum(dA2, axis=0,keepdims=True)\n",
    "    dA1 = np.dot(dA2, parameters[\"W2\"].T)\n",
    "    dZ1 = dA1 * (A1 * (1 - A1))\n",
    "    dW1 = np.dot(X.T, dZ1)\n",
    "    db1 = np.sum(dZ1, axis=0)\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return gradients, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParameters(parameters, gradients, learningRate):\n",
    "    parameters[\"W1\"] = parameters[\"W1\"] - learningRate * gradients[\"dW1\"]\n",
    "    parameters[\"b1\"] = parameters[\"b1\"] - learningRate * gradients[\"db1\"]\n",
    "    parameters[\"W2\"] = parameters[\"W2\"] - learningRate * gradients[\"dW2\"]\n",
    "    parameters[\"b2\"] = parameters[\"b2\"] - learningRate * gradients[\"db2\"]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, parameters, learningRate, numberOfIterations, printCost=False):\n",
    "    costs = []\n",
    "    for i in range(numberOfIterations):\n",
    "        gradients, cost = propagate(X, Y, parameters)\n",
    "        parameters = updateParameters(parameters, gradients, learningRate)\n",
    "        costs.append(cost)\n",
    "        if i % 100 == 0 and printCost:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    Z1 = np.dot(X, parameters[\"W1\"]) + parameters[\"b1\"]\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, parameters[\"W2\"]) + parameters[\"b2\"]\n",
    "    A2 = softmax(Z2)\n",
    "    return np.argmax(A2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 132400.40176590235\n",
      "Cost after iteration 100: 42764.27812233248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10313/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 200: 39962.974077592895\n",
      "Cost after iteration 300: 37948.635131375704\n",
      "Cost after iteration 400: 37190.733709314525\n",
      "Cost after iteration 500: 36863.885935666556\n",
      "Cost after iteration 600: 33642.342378776\n",
      "Cost after iteration 700: 34388.07751649178\n",
      "Cost after iteration 800: 34646.1160511067\n",
      "Cost after iteration 900: 33530.34789254052\n",
      "Cost after iteration 1000: 31029.99481889547\n",
      "Cost after iteration 1100: 30574.590681991154\n",
      "Cost after iteration 1200: 30277.59696615229\n",
      "Cost after iteration 1300: 30774.44383228022\n",
      "Cost after iteration 1400: 31064.170353721638\n",
      "Cost after iteration 1500: 30838.16485950695\n",
      "Cost after iteration 1600: 30521.0427235533\n",
      "Cost after iteration 1700: 30163.701314547125\n",
      "Cost after iteration 1800: 29937.146245432494\n",
      "Cost after iteration 1900: 29743.48213480076\n",
      "Cost after iteration 2000: 29608.058231934298\n",
      "Cost after iteration 2100: 29487.54784519617\n",
      "Cost after iteration 2200: 29338.418256139932\n",
      "Cost after iteration 2300: 29203.97650582283\n",
      "Cost after iteration 2400: 29056.984784071865\n",
      "Cost after iteration 2500: 28972.27041669444\n",
      "Cost after iteration 2600: 28860.338871085572\n",
      "Cost after iteration 2700: 28775.169908775864\n",
      "Cost after iteration 2800: 28740.17168436194\n",
      "Cost after iteration 2900: 28708.261284114007\n",
      "Cost after iteration 3000: 28633.232640909544\n",
      "Cost after iteration 3100: 28610.180422891604\n",
      "Cost after iteration 3200: 28552.584272370645\n",
      "Cost after iteration 3300: 28547.253154809485\n",
      "Cost after iteration 3400: 28506.421439629034\n",
      "Cost after iteration 3500: 28488.488867793258\n",
      "Cost after iteration 3600: 28453.146322770262\n",
      "Cost after iteration 3700: 28426.00191283832\n",
      "Cost after iteration 3800: 28480.469993159884\n",
      "Cost after iteration 3900: 28396.897772281216\n",
      "Cost after iteration 4000: 28376.031268210085\n",
      "Cost after iteration 4100: 28356.61128870377\n",
      "Cost after iteration 4200: 28350.34447372967\n",
      "Cost after iteration 4300: 28390.345664378092\n",
      "Cost after iteration 4400: 28317.621221886253\n",
      "Cost after iteration 4500: 28301.425761481954\n",
      "Cost after iteration 4600: 28275.938209845655\n",
      "Cost after iteration 4700: 28258.901901634545\n",
      "Cost after iteration 4800: 28237.30550281326\n",
      "Cost after iteration 4900: 28233.953624208738\n"
     ]
    }
   ],
   "source": [
    "parameters = initializeParameters(2, 15, 20)\n",
    "params, costs = optimize(X,Y_encoded, parameters, 0.00001, 5000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10313/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "11677 22988\n",
      "{0: 8203, 5: 10120, 1: 3045, 12: 679, 7: 334, 9: 281, 14: 326}\n",
      "{0: 7531, 7: 2199, 3: 1482, 5: 2776, 1: 2946, 13: 123, 11: 719, 4: 797, 9: 2487, 10: 172, 2: 820, 14: 262, 8: 55, 18: 79, 19: 78, 12: 264, 16: 55, 6: 16, 17: 105, 15: 22}\n",
      "{0: 6801, 5: 2698, 1: 1760, 7: 80, 9: 65, 14: 91, 12: 182}\n",
      "50.7960675134853\n"
     ]
    }
   ],
   "source": [
    "a = predict(X, params)\n",
    "i=18\n",
    "print(a[i])\n",
    "sum =0\n",
    "timesGuessedA = {}\n",
    "timesGuessedY = {}\n",
    "trafione = {}\n",
    "for i in range(a.shape[0]):\n",
    "    timesGuessedA[a[i]] = timesGuessedA.get(a[i], 0) + 1    \n",
    "    timesGuessedY[np.argmax(Y_encoded[i])] = timesGuessedY.get(np.argmax(Y_encoded[i]), 0) + 1\n",
    "    if a[i] == np.argmax(Y_encoded[i]):\n",
    "        trafione[a[i]] = trafione.get(a[i], 0) + 1\n",
    "        sum += 1\n",
    "\n",
    "print(sum,a.shape[0])\n",
    "print(timesGuessedA)\n",
    "print(timesGuessedY)\n",
    "print(trafione)\n",
    "print(sum/a.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2863 5747\n",
      "{5: 2579, 1: 729, 0: 2041, 7: 78, 12: 164, 9: 62, 14: 94}\n",
      "{7: 559, 2: 233, 0: 1815, 5: 703, 3: 377, 10: 47, 1: 734, 9: 631, 8: 11, 4: 192, 15: 12, 11: 185, 17: 34, 14: 64, 13: 31, 12: 67, 19: 16, 16: 13, 18: 19, 6: 4}\n",
      "{0: 1666, 5: 684, 1: 424, 7: 20, 9: 11, 12: 39, 14: 19}\n",
      "49.817295980511574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10313/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    }
   ],
   "source": [
    "a = predict(X_test, params)\n",
    "i=18\n",
    "print(a[i])\n",
    "sum =0\n",
    "timesGuessedA = {}\n",
    "timesGuessedY = {}\n",
    "trafione = {}\n",
    "for i in range(a.shape[0]):\n",
    "    timesGuessedA[a[i]] = timesGuessedA.get(a[i], 0) + 1    \n",
    "    timesGuessedY[np.argmax(Y_test_encoded[i])] = timesGuessedY.get(np.argmax(Y_test_encoded[i]), 0) + 1\n",
    "    if a[i] == np.argmax(Y_test_encoded[i]):\n",
    "        trafione[a[i]] = trafione.get(a[i], 0) + 1\n",
    "        sum += 1\n",
    "\n",
    "print(sum,a.shape[0])\n",
    "print(timesGuessedA)\n",
    "print(timesGuessedY)\n",
    "print(trafione)\n",
    "print(sum/a.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(costs[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
