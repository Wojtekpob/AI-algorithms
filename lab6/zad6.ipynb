{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, ratio):\n",
    "    np.random.shuffle(data)\n",
    "    train_size = int(len(data) * ratio)\n",
    "    train_set = data[:train_size]\n",
    "    test_set = data[train_size:]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeToMinutes(time):\n",
    "    splitted = time.split(\":\")\n",
    "    if int(splitted[0]) > 23 or int(splitted[1]) > 59:\n",
    "        raise ValueError\n",
    "    return int(splitted[0]) * 60 + int(splitted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTime(time):\n",
    "    minutes = timeToMinutes(time)\n",
    "    return  math.sin(minutes / (24 * 60)*math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(codesToIndexes):\n",
    "    data = []\n",
    "    for i in range(1, 70):\n",
    "        filePrefix = 'Diabetes-Data/data-'\n",
    "        if i < 10:\n",
    "            filePrefix += '0'\n",
    "        fileHandle = open(filePrefix+str(i), 'r')\n",
    "        for line in fileHandle:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                try:\n",
    "                    parts = line.split('\\t')\n",
    "                    time = processTime(parts[1])\n",
    "                    code = int(parts[2])\n",
    "                    if code not in codesToIndexes.keys():\n",
    "                        raise ValueError\n",
    "                    number = int(parts[3])\n",
    "                    data.append([time, code, number])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        \n",
    "        fileHandle.close()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeOutput(Y,codesToIndexes):\n",
    "    codesToIndexes = {33:0, 34:1, 35:2, 48:3, 57:4, 58:5, 59:6, 60:7, 61:8, 62:9, 63:10, 64:11, 65:12, 66:13, 67:14, 68:15, 69:16, 70:17, 71:18, 72:19}\n",
    "    Y_encoded = np.zeros((Y.shape[0], 20))\n",
    "    for i, code in enumerate(Y):\n",
    "        index = codesToIndexes[code]\n",
    "        Y_encoded[i, index] = 1\n",
    "    return Y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "codesToIndexes = {33:0, 34:1, 35:2, 48:3, 57:4, 58:5, 59:6, 60:7, 61:8, 62:9, 63:10, 64:11, 65:12, 66:13, 67:14, 68:15, 69:16, 70:17, 71:18, 72:19}\n",
    "data = np.array(loadData(codesToIndexes))\n",
    "data, test = splitData(data, 0.8)\n",
    "X = data[:, [0, 2]]\n",
    "X_test = test[:, [0, 2]]\n",
    "Y = data[:, 1]\n",
    "Y_test = test[:, 1]\n",
    "Y_encoded = encodeOutput(Y,codesToIndexes)\n",
    "Y_test_encoded = encodeOutput(Y_test,codesToIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters(nX, nH, nY):\n",
    "    W1 = np.random.randn(nX, nH)\n",
    "    b1 = np.zeros((1,nH))\n",
    "    b1 = np.random.randn(1,nH)\n",
    "    W2 = np.random.randn(nH,nY)\n",
    "    b2 = np.zeros((1,nY))\n",
    "    b2 = np.random.randn(1,nY)\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architektura sieci neuronowej\n",
    "\n",
    "- **Warstwa wejściowa:** N neurony (wejścia)\n",
    "- **Warstwy ukryte:** L warstw, każda z dowolną liczbą neuronów\n",
    "- **Warstwa wyjściowa:** K neuronów (klasyfikacja na K kategorii)\n",
    "\n",
    "### Funkcje aktywacji\n",
    "\n",
    "- **Warstwy ukryte:** Sigmoid\n",
    "  - $$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "- **Warstwa wyjściowa:** Softmax\n",
    "  - $$\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n",
    "\n",
    "### Propagacja w przód\n",
    "\n",
    "Dla każdej warstwy l (od 1 do L+1, gdzie L+1 to warstwa wyjściowa):\n",
    "\n",
    "1. **Sygnał wejściowy:** $$Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$$\n",
    "2. **Aktywacja:** \n",
    "   - Dla warstw ukrytych: $$A^{[l]} = \\sigma(Z^{[l]})$$\n",
    "   - Dla warstwy wyjściowej: $$A^{[L+1]} = \\text{Softmax}(Z^{[L+1]})$$\n",
    "\n",
    "### Wsteczna propagacja błędu\n",
    "\n",
    "1. **Błąd na wyjściu (warstwa L+1):**\n",
    "   - $$\\delta^{[L+1]} = A^{[L+1]} - Y$$\n",
    "\n",
    "Dla każdej warstwy l od L do 1:\n",
    "\n",
    "2. **Błąd dla warstwy l:**\n",
    "   - $$\\delta^{[l]} = (W^{[l+1]T} \\delta^{[l+1]}) \\odot \\sigma'(Z^{[l]})$$\n",
    "3. **Gradient dla wag i biasów:**\n",
    "   - $$\\nabla W^{[l]} = \\delta^{[l]} A^{[l-1]T}$$\n",
    "   - $$\\nabla b^{[l]} = \\sum(\\delta^{[l]}, \\text{axis} = 0)$$\n",
    "\n",
    "### Aktualizacja wag\n",
    "\n",
    "- Wagi i biasy są aktualizowane za pomocą metody spadku gradientu:\n",
    "  - $$W^{[l]} = W^{[l]} - \\alpha \\nabla W^{[l]}$$\n",
    "  - $$b^{[l]} = b^{[l]} - \\alpha \\nabla b^{[l]}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(Y, Y_hat):\n",
    "    return - np.sum(Y * np.log(Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    return np.exp(Z) / np.sum(np.exp(Z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(X, Y, parameters):\n",
    "    Z1 = np.dot(X, parameters[\"W1\"]) + parameters[\"b1\"]\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, parameters[\"W2\"]) + parameters[\"b2\"]\n",
    "    A2 = softmax(Z2)\n",
    "    cost = costFunction(Y, A2)\n",
    "    # pochodne funkcji straty:\n",
    "    dA2 = A2 - Y\n",
    "    dW2 = np.dot(A1.T,dA2) \n",
    "    db2 = np.sum(dA2, axis=0,keepdims=True)\n",
    "    dA1 = np.dot(dA2, parameters[\"W2\"].T)\n",
    "    dZ1 = dA1 * (A1 * (1 - A1))\n",
    "    dW1 = np.dot(X.T, dZ1)\n",
    "    db1 = np.sum(dZ1, axis=0)\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return gradients, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParameters(W1, b1, W2, b2, gradients, learningRate):\n",
    "    W1 = W1 - learningRate * gradients[\"dW1\"]\n",
    "    b1 = b1 - learningRate * gradients[\"db1\"]\n",
    "    W2 = W2 - learningRate * gradients[\"dW2\"]\n",
    "    b2 = b2 - learningRate * gradients[\"db2\"]\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, parameters, learningRate, numberOfIterations, printCost=False):\n",
    "    costs = []\n",
    "    for i in range(numberOfIterations):\n",
    "        gradients, cost = propagate(X, Y, parameters)\n",
    "        parameters = updateParameters(parameters, gradients, learningRate)\n",
    "        costs.append(cost)\n",
    "        if i % 100 == 0 and printCost:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    Z1 = np.dot(X, parameters[\"W1\"]) + parameters[\"b1\"]\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, parameters[\"W2\"]) + parameters[\"b2\"]\n",
    "    A2 = softmax(Z2)\n",
    "    return np.argmax(A2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10313/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 116117.91811552043\n",
      "Cost after iteration 100: 44520.01935853351\n",
      "Cost after iteration 200: 40562.47933919337\n",
      "Cost after iteration 300: 40899.934045497095\n",
      "Cost after iteration 400: 38917.756653436714\n",
      "Cost after iteration 500: 39420.437505948306\n",
      "Cost after iteration 600: 38259.836810596295\n",
      "Cost after iteration 700: 33248.70429841142\n",
      "Cost after iteration 800: 32549.342267071563\n",
      "Cost after iteration 900: 31527.49687447481\n",
      "Cost after iteration 1000: 31643.587158702914\n",
      "Cost after iteration 1100: 31040.126263063536\n",
      "Cost after iteration 1200: 30284.661600678264\n",
      "Cost after iteration 1300: 31448.474174188\n",
      "Cost after iteration 1400: 29903.25457135787\n",
      "Cost after iteration 1500: 29926.563232413995\n",
      "Cost after iteration 1600: 29508.331885950796\n",
      "Cost after iteration 1700: 29423.715652237137\n",
      "Cost after iteration 1800: 29326.70786634379\n",
      "Cost after iteration 1900: 30859.05621527065\n",
      "Cost after iteration 2000: 29392.540338271017\n",
      "Cost after iteration 2100: 30209.516087794265\n",
      "Cost after iteration 2200: 29888.717080977247\n",
      "Cost after iteration 2300: 29674.864165946776\n",
      "Cost after iteration 2400: 29566.75622700637\n",
      "Cost after iteration 2500: 29432.983242819428\n",
      "Cost after iteration 2600: 29323.115479817734\n",
      "Cost after iteration 2700: 29312.994868475846\n",
      "Cost after iteration 2800: 29140.638987948594\n",
      "Cost after iteration 2900: 29097.33866912931\n",
      "Cost after iteration 3000: 29146.4957850692\n",
      "Cost after iteration 3100: 29100.834198621797\n",
      "Cost after iteration 3200: 28986.255382947103\n",
      "Cost after iteration 3300: 29007.11140303467\n",
      "Cost after iteration 3400: 28946.640808948912\n",
      "Cost after iteration 3500: 28900.830886871787\n",
      "Cost after iteration 3600: 28834.182390508267\n",
      "Cost after iteration 3700: 28876.437001135226\n",
      "Cost after iteration 3800: 28761.865090639843\n",
      "Cost after iteration 3900: 28781.08969313812\n",
      "Cost after iteration 4000: 28786.372351383023\n",
      "Cost after iteration 4100: 28762.741659759133\n",
      "Cost after iteration 4200: 28743.534792108494\n",
      "Cost after iteration 4300: 28726.464399158645\n",
      "Cost after iteration 4400: 28710.697659455043\n",
      "Cost after iteration 4500: 28695.880816151235\n",
      "Cost after iteration 4600: 28681.845313672693\n",
      "Cost after iteration 4700: 28668.497713814733\n",
      "Cost after iteration 4800: 28655.77694081186\n",
      "Cost after iteration 4900: 28643.63703049827\n"
     ]
    }
   ],
   "source": [
    "parameters = initializeParameters(2, 15, 20)\n",
    "params, costs = optimize(X,Y_encoded, parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"], parameters[\"b2\"], 0.00001, 5000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10313/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "11472 22988\n",
      "{5: 10652, 0: 9016, 14: 1019, 1: 2149, 7: 152}\n",
      "{7: 2211, 1: 2934, 0: 7483, 5: 2806, 2: 845, 9: 2485, 15: 31, 17: 109, 3: 1496, 11: 705, 4: 774, 10: 186, 12: 255, 14: 282, 13: 122, 18: 79, 8: 48, 19: 72, 16: 53, 6: 12}\n",
      "{0: 7067, 5: 2785, 1: 1302, 14: 282, 7: 36}\n",
      "49.90429789455368\n"
     ]
    }
   ],
   "source": [
    "a = predict(X, params)\n",
    "i=18\n",
    "print(a[i])\n",
    "sum =0\n",
    "timesGuessedA = {}\n",
    "timesGuessedY = {}\n",
    "trafione = {}\n",
    "for i in range(a.shape[0]):\n",
    "    timesGuessedA[a[i]] = timesGuessedA.get(a[i], 0) + 1    \n",
    "    timesGuessedY[np.argmax(Y_encoded[i])] = timesGuessedY.get(np.argmax(Y_encoded[i]), 0) + 1\n",
    "    if a[i] == np.argmax(Y_encoded[i]):\n",
    "        trafione[a[i]] = trafione.get(a[i], 0) + 1\n",
    "        sum += 1\n",
    "\n",
    "print(sum,a.shape[0])\n",
    "print(timesGuessedA)\n",
    "print(timesGuessedY)\n",
    "print(trafione)\n",
    "print(sum/a.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2819 5747\n",
      "{1: 561, 0: 2231, 5: 2661, 7: 50, 14: 244}\n",
      "{1: 746, 0: 1863, 9: 633, 5: 673, 3: 363, 11: 199, 7: 547, 2: 208, 4: 215, 10: 33, 19: 22, 14: 44, 12: 76, 18: 19, 13: 32, 17: 30, 16: 15, 8: 18, 6: 8, 15: 3}\n",
      "{1: 334, 0: 1761, 5: 668, 7: 12, 14: 44}\n",
      "49.05167913694101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10313/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    }
   ],
   "source": [
    "a = predict(X_test, params)\n",
    "i=18\n",
    "print(a[i])\n",
    "sum =0\n",
    "timesGuessedA = {}\n",
    "timesGuessedY = {}\n",
    "trafione = {}\n",
    "for i in range(a.shape[0]):\n",
    "    timesGuessedA[a[i]] = timesGuessedA.get(a[i], 0) + 1    \n",
    "    timesGuessedY[np.argmax(Y_test_encoded[i])] = timesGuessedY.get(np.argmax(Y_test_encoded[i]), 0) + 1\n",
    "    if a[i] == np.argmax(Y_test_encoded[i]):\n",
    "        trafione[a[i]] = trafione.get(a[i], 0) + 1\n",
    "        sum += 1\n",
    "\n",
    "print(sum,a.shape[0])\n",
    "print(timesGuessedA)\n",
    "print(timesGuessedY)\n",
    "print(trafione)\n",
    "print(sum/a.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(costs[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
