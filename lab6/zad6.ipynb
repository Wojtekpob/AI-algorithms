{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, ratio):\n",
    "    np.random.shuffle(data)\n",
    "    train_size = int(len(data) * ratio)\n",
    "    train_set = data[:train_size]\n",
    "    test_set = data[train_size:]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeToMinutes(time):\n",
    "    splitted = time.split(\":\")\n",
    "    if int(splitted[0]) > 23 or int(splitted[1]) > 59:\n",
    "        raise ValueError\n",
    "    return int(splitted[0]) * 60 + int(splitted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTime(time):\n",
    "    minutes = timeToMinutes(time)\n",
    "    return  math.sin(minutes / (24 * 60)*math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(codesToIndexes):\n",
    "    data = []\n",
    "    for i in range(1, 70):\n",
    "        filePrefix = 'Diabetes-Data/data-'\n",
    "        if i < 10:\n",
    "            filePrefix += '0'\n",
    "        fileHandle = open(filePrefix+str(i), 'r')\n",
    "        for line in fileHandle:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                try:\n",
    "                    parts = line.split('\\t')\n",
    "                    time = processTime(parts[1])\n",
    "                    code = int(parts[2])\n",
    "                    if code not in codesToIndexes.keys():\n",
    "                        raise ValueError\n",
    "                    number = int(parts[3])\n",
    "                    data.append([time, code, number])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        \n",
    "        fileHandle.close()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeOutput(Y,codesToIndexes):\n",
    "    codesToIndexes = {33:0, 34:1, 35:2, 48:3, 57:4, 58:5, 59:6, 60:7, 61:8, 62:9, 63:10, 64:11, 65:12, 66:13, 67:14, 68:15, 69:16, 70:17, 71:18, 72:19}\n",
    "    Y_encoded = np.zeros((Y.shape[0], 20))\n",
    "    for i, code in enumerate(Y):\n",
    "        index = codesToIndexes[code]\n",
    "        Y_encoded[i, index] = 1\n",
    "    return Y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "codesToIndexes = {33:0, 34:1, 35:2, 48:3, 57:4, 58:5, 59:6, 60:7, 61:8, 62:9, 63:10, 64:11, 65:12, 66:13, 67:14, 68:15, 69:16, 70:17, 71:18, 72:19}\n",
    "data = np.array(loadData(codesToIndexes))\n",
    "data, test = splitData(data, 0.8)\n",
    "X = data[:, [0, 2]]\n",
    "X_test = test[:, [0, 2]]\n",
    "Y = data[:, 1]\n",
    "Y_test = test[:, 1]\n",
    "Y_encoded = encodeOutput(Y,codesToIndexes)\n",
    "Y_test_encoded = encodeOutput(Y_test,codesToIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters(nX, nH, nY, numberOfHiddenLayers=1):\n",
    "    parameters = {}\n",
    "    if numberOfHiddenLayers < 1:\n",
    "        raise ValueError   \n",
    "    if numberOfHiddenLayers == 1:\n",
    "        parameters[\"W1\"] = np.random.randn(nX, nH)\n",
    "        parameters[\"b1\"] = np.zeros((1,nH))\n",
    "    if numberOfHiddenLayers > 1:\n",
    "        parameters[\"W1\"] = np.random.randn(nX, nH[0])\n",
    "        parameters[\"b1\"] = np.zeros((1,nH[0]))\n",
    "        for i in range(2, numberOfHiddenLayers+1):\n",
    "            parameters[\"W\"+str(i+1)] = np.random.randn(nH[i-2], nH[i-1])\n",
    "            parameters[\"b\"+str(i+1)] = np.zeros((1,nH[i-1]))\n",
    "    parameters[\"W\"+str(numberOfHiddenLayers+1)] = np.random.randn(nH[-1], nY)\n",
    "    parameters[\"b\"+str(numberOfHiddenLayers+1)] = np.zeros((1,nY))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architektura sieci neuronowej\n",
    "\n",
    "- **Warstwa wejściowa:** N neurony (wejścia)\n",
    "- **Warstwy ukryte:** L warstw, każda z dowolną liczbą neuronów\n",
    "- **Warstwa wyjściowa:** K neuronów (klasyfikacja na K kategorii)\n",
    "\n",
    "### Funkcje aktywacji\n",
    "\n",
    "- **Warstwy ukryte:** Sigmoid\n",
    "  - $$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "- **Warstwa wyjściowa:** Softmax\n",
    "  - $$\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n",
    "\n",
    "### Propagacja w przód\n",
    "\n",
    "Dla każdej warstwy l (od 1 do L+1, gdzie L+1 to warstwa wyjściowa):\n",
    "\n",
    "1. **Sygnał wejściowy:** $$Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$$\n",
    "2. **Aktywacja:** \n",
    "   - Dla warstw ukrytych: $$A^{[l]} = \\sigma(Z^{[l]})$$\n",
    "   - Dla warstwy wyjściowej: $$A^{[L+1]} = \\text{Softmax}(Z^{[L+1]})$$\n",
    "\n",
    "### Wsteczna propagacja błędu\n",
    "\n",
    "1. **Błąd na wyjściu (warstwa L+1):**\n",
    "   - $$\\delta^{[L+1]} = A^{[L+1]} - Y$$\n",
    "\n",
    "Dla każdej warstwy l od L do 1:\n",
    "\n",
    "2. **Błąd dla warstwy l:**\n",
    "   - $$\\delta^{[l]} = (W^{[l+1]T} \\delta^{[l+1]}) \\odot \\sigma'(Z^{[l]})$$\n",
    "3. **Gradient dla wag i biasów:**\n",
    "   - $$\\nabla W^{[l]} = \\delta^{[l]} A^{[l-1]T}$$\n",
    "   - $$\\nabla b^{[l]} = \\sum(\\delta^{[l]}, \\text{axis} = 0)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(Y, Y_hat):\n",
    "    return - np.sum(Y * np.log(Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    return np.exp(Z) / np.sum(np.exp(Z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(X, Y, parameters):\n",
    "    \n",
    "    Z1 = np.dot(X, parameters[\"W1\"]) + parameters[\"b1\"]\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, parameters[\"W2\"]) + parameters[\"b2\"]\n",
    "    A2 = softmax(Z2)\n",
    "    cost = costFunction(Y, A2)\n",
    "    # pochodne funkcji straty:\n",
    "    dA2 = A2 - Y\n",
    "    dW2 = np.dot(A1.T,dA2) \n",
    "    db2 = np.sum(dA2, axis=0,keepdims=True)\n",
    "    dA1 = np.dot(dA2, parameters[\"W2\"].T)\n",
    "    dZ1 = dA1 * (A1 * (1 - A1))\n",
    "    dW1 = np.dot(X.T, dZ1)\n",
    "    db1 = np.sum(dZ1, axis=0)\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return gradients, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Aktualizacja wag\n",
    "\n",
    "- Wagi i biasy są aktualizowane za pomocą metody spadku gradientu:\n",
    "  - $$W^{[l]} = W^{[l]} - \\alpha \\nabla W^{[l]}$$\n",
    "  - $$b^{[l]} = b^{[l]} - \\alpha \\nabla b^{[l]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParameters(parameters, gradients, learningRate):\n",
    "    parameters[\"W1\"] = parameters[\"W1\"] - learningRate * gradients[\"dW1\"]\n",
    "    parameters[\"b1\"] = parameters[\"b1\"] - learningRate * gradients[\"db1\"]\n",
    "    parameters[\"W2\"] = parameters[\"W2\"] - learningRate * gradients[\"dW2\"]\n",
    "    parameters[\"b2\"] = parameters[\"b2\"] - learningRate * gradients[\"db2\"]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, parameters, learningRate, numberOfIterations, printCost=False):\n",
    "    costs = []\n",
    "    for i in range(numberOfIterations):\n",
    "        gradients, cost = propagate(X, Y, parameters)\n",
    "        parameters = updateParameters(parameters, gradients, learningRate)\n",
    "        costs.append(cost)\n",
    "        if i % 100 == 0 and printCost:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    Z = X\n",
    "    for i in range(1, len(parameters)//2):\n",
    "        Z = np.dot(Z, parameters[\"W\"+str(i)]) + parameters[\"b\"+str(i)]\n",
    "        Z = sigmoid(Z)\n",
    "    Z = np.dot(Z, parameters[\"W\"+str(len(parameters)//2)]) + parameters[\"b\"+str(len(parameters)//2)]\n",
    "    Z = softmax(Z)\n",
    "    return np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19238/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 88161.49486018588\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m parameters \u001b[38;5;241m=\u001b[39m initializeParameters(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m params, costs \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(X, Y, parameters, learningRate, numberOfIterations, printCost)\u001b[0m\n\u001b[1;32m      2\u001b[0m costs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numberOfIterations):\n\u001b[0;32m----> 4\u001b[0m     gradients, cost \u001b[38;5;241m=\u001b[39m \u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m updateParameters(parameters, gradients, learningRate)\n\u001b[1;32m      6\u001b[0m     costs\u001b[38;5;241m.\u001b[39mappend(cost)\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(X, Y, parameters)\u001b[0m\n\u001b[1;32m      3\u001b[0m Z1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m A1 \u001b[38;5;241m=\u001b[39m sigmoid(Z1)\n\u001b[0;32m----> 5\u001b[0m Z2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m A2 \u001b[38;5;241m=\u001b[39m softmax(Z2)\n\u001b[1;32m      7\u001b[0m cost \u001b[38;5;241m=\u001b[39m costFunction(Y, A2)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = initializeParameters(2, 15, 20)\n",
    "params, costs = optimize(X,Y_encoded, parameters, 0.00001, 5000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10313/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11675 22988\n",
      "{12: 686, 0: 8114, 5: 10494, 1: 3078, 14: 336, 7: 280}\n",
      "{15: 25, 0: 7486, 5: 2801, 1: 2918, 9: 2518, 11: 748, 7: 2189, 3: 1454, 4: 796, 12: 267, 2: 834, 14: 269, 18: 78, 17: 112, 10: 166, 16: 56, 13: 128, 8: 56, 19: 73, 6: 14}\n",
      "{0: 6774, 5: 2763, 1: 1790, 12: 180, 14: 94, 7: 74}\n",
      "50.78736732208109\n"
     ]
    }
   ],
   "source": [
    "a = predict(X, params)\n",
    "i=18\n",
    "print(a[i])\n",
    "sum =0\n",
    "timesGuessedA = {}\n",
    "timesGuessedY = {}\n",
    "trafione = {}\n",
    "for i in range(a.shape[0]):\n",
    "    timesGuessedA[a[i]] = timesGuessedA.get(a[i], 0) + 1    \n",
    "    timesGuessedY[np.argmax(Y_encoded[i])] = timesGuessedY.get(np.argmax(Y_encoded[i]), 0) + 1\n",
    "    if a[i] == np.argmax(Y_encoded[i]):\n",
    "        trafione[a[i]] = trafione.get(a[i], 0) + 1\n",
    "        sum += 1\n",
    "\n",
    "print(sum,a.shape[0])\n",
    "print(timesGuessedA)\n",
    "print(timesGuessedY)\n",
    "print(trafione)\n",
    "print(sum/a.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2859 5747\n",
      "{5: 2615, 1: 781, 0: 2034, 12: 155, 14: 86, 7: 76}\n",
      "{5: 678, 1: 762, 0: 1860, 7: 569, 9: 600, 3: 405, 4: 193, 11: 156, 16: 12, 17: 27, 2: 219, 19: 21, 14: 57, 8: 10, 12: 64, 13: 26, 10: 53, 18: 20, 15: 9, 6: 6}\n",
      "{5: 669, 1: 453, 0: 1666, 14: 16, 7: 16, 12: 39}\n",
      "49.74769444927789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10313/70635953.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-Z))\n"
     ]
    }
   ],
   "source": [
    "a = predict(X_test, params)\n",
    "i=18\n",
    "print(a[i])\n",
    "sum =0\n",
    "timesGuessedA = {}\n",
    "timesGuessedY = {}\n",
    "trafione = {}\n",
    "for i in range(a.shape[0]):\n",
    "    timesGuessedA[a[i]] = timesGuessedA.get(a[i], 0) + 1    \n",
    "    timesGuessedY[np.argmax(Y_test_encoded[i])] = timesGuessedY.get(np.argmax(Y_test_encoded[i]), 0) + 1\n",
    "    if a[i] == np.argmax(Y_test_encoded[i]):\n",
    "        trafione[a[i]] = trafione.get(a[i], 0) + 1\n",
    "        sum += 1\n",
    "\n",
    "print(sum,a.shape[0])\n",
    "print(timesGuessedA)\n",
    "print(timesGuessedY)\n",
    "print(trafione)\n",
    "print(sum/a.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minitializeParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m, in \u001b[0;36minitializeParameters\u001b[0;34m(nX, nH, nY, numberOfHiddenLayers)\u001b[0m\n\u001b[1;32m     12\u001b[0m         parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(nH[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], nH[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     13\u001b[0m         parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m,nH[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 14\u001b[0m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(numberOfHiddenLayers\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(numberOfHiddenLayers\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m,nY))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parameters\n",
      "File \u001b[0;32mmtrand.pyx:1270\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randn\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mmtrand.pyx:1431\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.standard_normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:636\u001b[0m, in \u001b[0;36mnumpy.random._common.cont\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "initializeParameters(2, [1,2], 20, 2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
